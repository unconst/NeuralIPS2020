%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% REFERENCES FOR PHD WORK
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{wang2018glue,
  title={Glue: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{hinton2014dark,
  title={Dark knowledge},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={Presented as the keynote in BayLearn},
  volume={2},
  year={2014}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{chollet2019measure,
  title={On the Measure of Intelligence},
  author={Chollet, Francis},
  journal={arXiv preprint arXiv:/1911.01547},
  year={2019}
}

@article{Riabinin2020learningathome,
  title={Learning@Home: Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts
},
  author={Riabinin, Maksim and Gusev, Anton },
  journal={arXiv preprint arXiv:/2002.04013},
  year={2020}
}


@article{lecun1989optimalbraindamage,
  title={Optimal Brain Damage},
  author={LeCun, Yann, and Denker John S, and Solla Sara A},
  journal={Advances in Neural Information Processing Systems 2 (NIPS)},
  year={1989}
}

@article{Bathina1989neurotrophin,
  title={Brain-derived neurotrophic factor and its clinical implications},
  author={Bathina S and Das UN},
  journal={Arch Med Sci. 2015;11(6):1164–1178. doi:10.5114/aoms.2015.56342},
  year={2015}
}

@article{Caruana2006compression,
  title={Model compression.},
  author={Cristian Bucila, Rich Caruana, and Alexandru Niculescu-Mizil},
  journal={In KDD},
  year={2006}
}

@article{Sanh2019DistilBERT,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor; Debut, Lysandre; Chaumond, Julien; Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@misc{shazeer2017outrageously,
    title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
    author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
    year={2017},
    eprint={1701.06538},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@misc{huo2018decoupled,
    title={Decoupled Parallel Backpropagation with Convergence Guarantee},
    author={Zhouyuan Huo and Bin Gu and Qian Yang and Heng Huang},
    year={2018},
    eprint={1804.10574},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{yu2017nisp,
    title={NISP: Pruning Networks using Neuron Importance Score Propagation},
    author={Ruichi Yu and Ang Li and Chun-Fu Chen and Jui-Hsin Lai and Vlad I. Morariu and Xintong Han and Mingfei Gao and Ching-Yung Lin and Larry S. Davis},
    year={2017},
    eprint={1711.05908},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{balduzzi2020smooth,
    title={Smooth markets: A basic mechanism for organizing gradient-based learners},
    author={David Balduzzi and Wojciech M Czarnecki and Thomas W Anthony and Ian M Gemp and Edward Hughes and Joel Z Leibo and Georgios Piliouras and Thore Graepel},
    year={2020},
    eprint={2001.04678},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{tu2016reducing,
  title={Reducing the model order of deep neural networks using information theory},
  author={Tu, Ming and Berisha, Visar and Cao, Yu and Seo, Jae-sun},
  booktitle={2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)},
  pages={93--98},
  year={2016},
  organization={IEEE}
}


@misc{alex2014cortical,
    title={Cortical Processing with Thermodynamic-RAM},
    author={M. Alexander Nugent and Timothy W. Molter},
    year={2014},
    eprint={1408.3215},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@misc{dtting2017optimal,
    title={Optimal Auctions through Deep Learning},
    author={Paul Dütting and Zhe Feng and Harikrishna Narasimhan and David C. Parkes and Sai Srivatsa Ravindranath},
    year={2017},
    eprint={1706.03459},
    archivePrefix={arXiv},
    primaryClass={cs.GT}
}

@misc{lample2019crosslingual,
    title={Cross-lingual Language Model Pretraining},
    author={Guillaume Lample and Alexis Conneau},
    year={2019},
    eprint={1901.07291},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@misc{kaiser2017model,
    title={One Model To Learn Them All},
    author={Lukasz Kaiser and Aidan N. Gomez and Noam Shazeer and Ashish Vaswani and Niki Parmar and Llion Jones and Jakob Uszkoreit},
    year={2017},
    eprint={1706.05137},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@inproceedings{wang2019superglue,
	title={Superglue: A stickier benchmark for general-purpose language understanding systems},
	author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
	booktitle={Advances in Neural Information Processing Systems},
	pages={3261--3275},
	year={2019}
}